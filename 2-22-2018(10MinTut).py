Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import pandas as pd
>>> import numpy as np
>>> import matplotlib.pyplot as plt
>>> s = pd.Series([1,3,5,np.nan,6,8])
>>> s
0    1.0
1    3.0
2    5.0
3    NaN
4    6.0
5    8.0
dtype: float64
>>> dates = pd.date_range('20130101',periods=6)
>>> dates
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))
>>> df
                   A         B         C         D
2013-01-01  2.137210 -1.353613 -1.352080  0.066339
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-03 -0.855513  0.391119  0.002675  0.028698
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
2013-01-05  0.757864  0.419163 -1.809178  1.362507
2013-01-06  0.233945 -1.288125  0.627911  0.446794

>>> df2 = pd.DataFrame({ 'A' : 1.,
... 'B' : pd.Timestamp('20130102'),
...  'C' : pd.Series(1,index=list(range(4)),dtype='float32'),
...  'D' : np.array([3] * 4,dtype='int32'),
...  'E' : pd.Categorical(["test","train","test","train"]),
... 'F' : 'foo' })
>>> df2
     A          B    C  D      E    F
0  1.0 2013-01-02  1.0  3   test  foo
1  1.0 2013-01-02  1.0  3  train  foo
2  1.0 2013-01-02  1.0  3   test  foo
3  1.0 2013-01-02  1.0  3  train  foo
>>> df2.dtypes
A           float64
B    datetime64[ns]
C           float32
D             int32
E          category
F            object
dtype: object
>>> df2.<TAB>
  File "<stdin>", line 1
    df2.<TAB>
        ^

SyntaxError: invalid syntax
>>> df.head()
                   A         B         C         D
2013-01-01  2.137210 -1.353613 -1.352080  0.066339
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-03 -0.855513  0.391119  0.002675  0.028698
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
2013-01-05  0.757864  0.419163 -1.809178  1.362507
>>> df.tail(3)
                   A         B         C         D
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
2013-01-05  0.757864  0.419163 -1.809178  1.362507
2013-01-06  0.233945 -1.288125  0.627911  0.446794
>>> df.index
DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',
               '2013-01-05', '2013-01-06'],
              dtype='datetime64[ns]', freq='D')
>>> df.columns
Index(['A', 'B', 'C', 'D'], dtype='object')
>>> df.values
array([[ 2.13720983, -1.35361309, -1.35207982,  0.06633857],
       [ 1.29947369, -1.05203495, -1.35449759, -0.10126774],
       [-0.85551256,  0.39111934,  0.00267474,  0.02869836],
       [ 1.01017554, -0.03653237, -0.23046928,  0.2221567 ],
       [ 0.75786448,  0.41916314, -1.80917806,  1.3625068 ],
       [ 0.23394504, -1.28812512,  0.62791144,  0.44679366]])
>>> df.describes()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\python\lib\site-packages\pandas\core\generic.py", line 3614, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute 'describes'
>>> df.describe()
              A         B         C         D
count  6.000000  6.000000  6.000000  6.000000
mean   0.763859 -0.486671 -0.685940  0.337538
std    1.013593  0.837524  0.955010  0.536152
min   -0.855513 -1.353613 -1.809178 -0.101268
25%    0.364925 -1.229103 -1.353893  0.038108
50%    0.884020 -0.544284 -0.791275  0.144248
75%    1.227149  0.284206 -0.055611  0.390634
max    2.137210  0.419163  0.627911  1.362507
>>> df.T
   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06
A    2.137210    1.299474   -0.855513    1.010176    0.757864    0.233945
B   -1.353613   -1.052035    0.391119   -0.036532    0.419163   -1.288125
C   -1.352080   -1.354498    0.002675   -0.230469   -1.809178    0.627911
D    0.066339   -0.101268    0.028698    0.222157    1.362507    0.446794
>>> df.sort_index(axis=1, ascending=False)
                   D         C         B         A
2013-01-01  0.066339 -1.352080 -1.353613  2.137210
2013-01-02 -0.101268 -1.354498 -1.052035  1.299474
2013-01-03  0.028698  0.002675  0.391119 -0.855513
2013-01-04  0.222157 -0.230469 -0.036532  1.010176
2013-01-05  1.362507 -1.809178  0.419163  0.757864
2013-01-06  0.446794  0.627911 -1.288125  0.233945
>>> df.sort_values(by='B')
                   A         B         C         D
2013-01-01  2.137210 -1.353613 -1.352080  0.066339
2013-01-06  0.233945 -1.288125  0.627911  0.446794
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
2013-01-03 -0.855513  0.391119  0.002675  0.028698
2013-01-05  0.757864  0.419163 -1.809178  1.362507
>>> df['A']
2013-01-01    2.137210
2013-01-02    1.299474
2013-01-03   -0.855513
2013-01-04    1.010176
2013-01-05    0.757864
2013-01-06    0.233945
Freq: D, Name: A, dtype: float64
>>> df[0:3]
                   A         B         C         D
2013-01-01  2.137210 -1.353613 -1.352080  0.066339
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-03 -0.855513  0.391119  0.002675  0.028698
>>>  df['20130102':'20130104']
  File "<stdin>", line 1
    df['20130102':'20130104']
    ^
IndentationError: unexpected indent
>>> df['20130102':'20130104']
                   A         B         C         D
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-03 -0.855513  0.391119  0.002675  0.028698
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
>>> df.loc[dates[0]]
A    2.137210
B   -1.353613
C   -1.352080
D    0.066339
Name: 2013-01-01 00:00:00, dtype: float64
>>> df.loc[:,['A','B']]
                   A         B
2013-01-01  2.137210 -1.353613
2013-01-02  1.299474 -1.052035
2013-01-03 -0.855513  0.391119
2013-01-04  1.010176 -0.036532
2013-01-05  0.757864  0.419163
2013-01-06  0.233945 -1.288125
>>> df.loc['20130102':'20130104',['A','B']]
                   A         B
2013-01-02  1.299474 -1.052035
2013-01-03 -0.855513  0.391119
2013-01-04  1.010176 -0.036532
>>> df.loc['20130102',['A','B']]
A    1.299474
B   -1.052035
Name: 2013-01-02 00:00:00, dtype: float64
>>> df.loc[dates[0],'A']
2.1372098308666803
>>> df.at[dates[0],'A']
2.1372098308666803
>>> df.iloc[3]
A    1.010176
B   -0.036532
C   -0.230469
D    0.222157
Name: 2013-01-04 00:00:00, dtype: float64
>>> df.iloc[3:5,0:2]
                   A         B
2013-01-04  1.010176 -0.036532
2013-01-05  0.757864  0.419163
>>> df.iloc[[1,2,4],[0,2]]
                   A         C
2013-01-02  1.299474 -1.354498
2013-01-03 -0.855513  0.002675
2013-01-05  0.757864 -1.809178
>>> df.iloc[1:3,:]
                   A         B         C         D
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-03 -0.855513  0.391119  0.002675  0.028698
>>>  df.iloc[:,1:3]
  File "<stdin>", line 1
    df.iloc[:,1:3]
    ^
IndentationError: unexpected indent
>>> df.iloc[:,1:3]
                   B         C
2013-01-01 -1.353613 -1.352080
2013-01-02 -1.052035 -1.354498
2013-01-03  0.391119  0.002675
2013-01-04 -0.036532 -0.230469
2013-01-05  0.419163 -1.809178
2013-01-06 -1.288125  0.627911
>>> df.iloc[1,1]
-1.0520349465505423
>>> df.iat[1,1]
-1.0520349465505423
>>> df[df.A > 0]
                   A         B         C         D
2013-01-01  2.137210 -1.353613 -1.352080  0.066339
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268
2013-01-04  1.010176 -0.036532 -0.230469  0.222157
2013-01-05  0.757864  0.419163 -1.809178  1.362507
2013-01-06  0.233945 -1.288125  0.627911  0.446794
>>> df[df > 0]
                   A         B         C         D
2013-01-01  2.137210       NaN       NaN  0.066339
2013-01-02  1.299474       NaN       NaN       NaN
2013-01-03       NaN  0.391119  0.002675  0.028698
2013-01-04  1.010176       NaN       NaN  0.222157
2013-01-05  0.757864  0.419163       NaN  1.362507
2013-01-06  0.233945       NaN  0.627911  0.446794
>>> df2 = df.copy()
>>> df2['E'] = ['one', 'one','two','three','four','three']
>>> df2
                   A         B         C         D      E
2013-01-01  2.137210 -1.353613 -1.352080  0.066339    one
2013-01-02  1.299474 -1.052035 -1.354498 -0.101268    one
2013-01-03 -0.855513  0.391119  0.002675  0.028698    two
2013-01-04  1.010176 -0.036532 -0.230469  0.222157  three
2013-01-05  0.757864  0.419163 -1.809178  1.362507   four
2013-01-06  0.233945 -1.288125  0.627911  0.446794  three
>>> df2[df2['E'].isin(['two','four'])]
                   A         B         C         D     E
2013-01-03 -0.855513  0.391119  0.002675  0.028698   two
2013-01-05  0.757864  0.419163 -1.809178  1.362507  four
>>> s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))
>>> s1
2013-01-02    1
2013-01-03    2
2013-01-04    3
2013-01-05    4
2013-01-06    5
2013-01-07    6
Freq: D, dtype: int64
>>> df['F'] = s1
>>> df.at[dates[0],'A'] = 0
>>> df.iat[0,1] = 0
>>> df.loc[:,'D'] = np.array([5] * len(df))
>>> df
                   A         B         C  D    F
2013-01-01  0.000000  0.000000 -1.352080  5  NaN
2013-01-02  1.299474 -1.052035 -1.354498  5  1.0
2013-01-03 -0.855513  0.391119  0.002675  5  2.0
2013-01-04  1.010176 -0.036532 -0.230469  5  3.0
2013-01-05  0.757864  0.419163 -1.809178  5  4.0
2013-01-06  0.233945 -1.288125  0.627911  5  5.0
>>> df2 = df.copy()
>>> df2[df2 > 0] = -df2
>>> df2
                   A         B         C  D    F
2013-01-01  0.000000  0.000000 -1.352080 -5  NaN
2013-01-02 -1.299474 -1.052035 -1.354498 -5 -1.0
2013-01-03 -0.855513 -0.391119 -0.002675 -5 -2.0
2013-01-04 -1.010176 -0.036532 -0.230469 -5 -3.0
2013-01-05 -0.757864 -0.419163 -1.809178 -5 -4.0
2013-01-06 -0.233945 -1.288125 -0.627911 -5 -5.0
>>> df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])
>>> df1.loc[dates[0]:dates[1],'E'] = 1
>>> df1
                   A         B         C  D    F    E
2013-01-01  0.000000  0.000000 -1.352080  5  NaN  1.0
2013-01-02  1.299474 -1.052035 -1.354498  5  1.0  1.0
2013-01-03 -0.855513  0.391119  0.002675  5  2.0  NaN
2013-01-04  1.010176 -0.036532 -0.230469  5  3.0  NaN
>>> df1.dropna(how='any')
                   A         B         C  D    F    E
2013-01-02  1.299474 -1.052035 -1.354498  5  1.0  1.0
>>> df1.fillna(value=5)
                   A         B         C  D    F    E
2013-01-01  0.000000  0.000000 -1.352080  5  5.0  1.0
2013-01-02  1.299474 -1.052035 -1.354498  5  1.0  1.0
2013-01-03 -0.855513  0.391119  0.002675  5  2.0  5.0
2013-01-04  1.010176 -0.036532 -0.230469  5  3.0  5.0
>>> pd.isna(df1)
                A      B      C      D      F      E
2013-01-01  False  False  False  False   True  False
2013-01-02  False  False  False  False  False  False
2013-01-03  False  False  False  False  False   True
2013-01-04  False  False  False  False  False   True
>>> df.mean()
A    0.407658
B   -0.261068
C   -0.685940
D    5.000000
F    3.000000
dtype: float64
>>> df.mean(1)
2013-01-01    0.911980
2013-01-02    0.978588
2013-01-03    1.307656
2013-01-04    1.748635
2013-01-05    1.673570
2013-01-06    1.914746
Freq: D, dtype: float64
>>> s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)
>>> s
2013-01-01    NaN
2013-01-02    NaN
2013-01-03    1.0
2013-01-04    3.0
2013-01-05    5.0
2013-01-06    NaN
Freq: D, dtype: float64
>>> df.sub(s, axis='index')
                   A         B         C    D    F
2013-01-01       NaN       NaN       NaN  NaN  NaN
2013-01-02       NaN       NaN       NaN  NaN  NaN
2013-01-03 -1.855513 -0.608881 -0.997325  4.0  1.0
2013-01-04 -1.989824 -3.036532 -3.230469  2.0  0.0
2013-01-05 -4.242136 -4.580837 -6.809178  0.0 -1.0
2013-01-06       NaN       NaN       NaN  NaN  NaN
>>> df.apply(np.cumsum)
                   A         B         C   D     F
2013-01-01  0.000000  0.000000 -1.352080   5   NaN
2013-01-02  1.299474 -1.052035 -2.706577  10   1.0
2013-01-03  0.443961 -0.660916 -2.703903  15   3.0
2013-01-04  1.454137 -0.697448 -2.934372  20   6.0
2013-01-05  2.212001 -0.278285 -4.743550  25  10.0
2013-01-06  2.445946 -1.566410 -4.115639  30  15.0
>>> df.apply(lambda x: x.max() - x.min())
A    2.154986
B    1.707288
C    2.437089
D    0.000000
F    4.000000
dtype: float64
>>>  s = pd.Series(np.random.randint(0, 7, size=10))
  File "<stdin>", line 1
    s = pd.Series(np.random.randint(0, 7, size=10))
    ^
IndentationError: unexpected indent
>>> s = pd.Series(np.random.randint(0, 7, size=10))
>>> s
0    6
1    6
2    2
3    4
4    0
5    2
6    0
7    0
8    2
9    6
dtype: int32
>>> s.value_counts()
6    3
2    3
0    3
4    1
dtype: int64
>>> s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
>>> s.str.lower()
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object
>>>  df = pd.DataFrame(np.random.randn(10, 4))
  File "<stdin>", line 1
    df = pd.DataFrame(np.random.randn(10, 4))
    ^
IndentationError: unexpected indent
>>> df = pd.DataFrame(np.random.randn(10, 4))
>>> df
          0         1         2         3
0 -0.957100  1.184230  0.203693  2.078144
1 -2.225077 -0.786043 -0.461033 -0.272563
2  0.652768 -0.038169  0.136476  0.549844
3 -1.024031  0.738176  0.867494  0.100913
4 -1.317426 -0.143176 -0.527278  0.480066
5  1.487473  0.416037  0.858850  0.596791
6 -1.203600  1.354218  0.212270 -0.393836
7 -0.107276  0.930813  0.365993 -0.814945
8 -0.295313  1.938763 -0.097084  1.191618
9 -0.663157 -0.177650 -1.830314  0.600484
>>> pieces = [df[:3], df[3:7], df[7:]]
>>> pd.concat(pieces)
          0         1         2         3
0 -0.957100  1.184230  0.203693  2.078144
1 -2.225077 -0.786043 -0.461033 -0.272563
2  0.652768 -0.038169  0.136476  0.549844
3 -1.024031  0.738176  0.867494  0.100913
4 -1.317426 -0.143176 -0.527278  0.480066
5  1.487473  0.416037  0.858850  0.596791
6 -1.203600  1.354218  0.212270 -0.393836
7 -0.107276  0.930813  0.365993 -0.814945
8 -0.295313  1.938763 -0.097084  1.191618
9 -0.663157 -0.177650 -1.830314  0.600484
>>> left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})
>>> right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})
>>> left
   key  lval
0  foo     1
1  foo     2
>>> right
   key  rval
0  foo     4
1  foo     5
>>> pd.merge(left, right, on='key')
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5
>>> left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})
>>> right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})
>>> left
   key  lval
0  foo     1
1  bar     2
>>> right
   key  rval
0  foo     4
1  bar     5
>>> pd.merge(left, right, on='key')
   key  lval  rval
0  foo     1     4
1  bar     2     5
>>> df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
>>> df
          A         B         C         D
0  0.536943  1.988918 -0.550469 -0.854790
1 -0.750129  0.026473  1.516159  1.631126
2 -0.202263 -1.252759  0.014728 -0.183386
3 -0.696748 -0.805289  0.342106 -1.583954
4  0.936531  1.076050 -0.078307  0.111626
5  0.681202  1.772616  0.675602  0.610926
6  1.235858 -0.213729  0.429794  0.550669
7 -0.329214 -0.192592  0.700140  1.776438
>>> s = df.iloc[3]
>>> df.append(s, ignore_index=True)
          A         B         C         D
0  0.536943  1.988918 -0.550469 -0.854790
1 -0.750129  0.026473  1.516159  1.631126
2 -0.202263 -1.252759  0.014728 -0.183386
3 -0.696748 -0.805289  0.342106 -1.583954
4  0.936531  1.076050 -0.078307  0.111626
5  0.681202  1.772616  0.675602  0.610926
6  1.235858 -0.213729  0.429794  0.550669
7 -0.329214 -0.192592  0.700140  1.776438
8 -0.696748 -0.805289  0.342106 -1.583954
>>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
... 'foo', 'bar', 'foo', 'foo'],
... 'B' : ['one', 'one', 'two', 'three',
... 'two', 'two', 'one', 'three'],
... 'C' : np.random.randn(8),
... 'D' : np.random.randn(8)})
>>> df
     A      B         C         D
0  foo    one  0.544852 -1.492598
1  bar    one  0.558751  1.100566
2  foo    two  0.024862  0.890895
3  bar  three -0.552441  0.493178
4  foo    two  0.766409 -0.143223
5  bar    two -0.550180 -0.158604
6  foo    one -0.276810 -0.967970
7  foo  three -0.089265  0.631529
>>> df.groupby('A').sum()
            C         D
A
bar -0.543870  1.435140
foo  0.970047 -1.081369
>>> df.groupby(['A','B']).sum()
                  C         D
A   B
bar one    0.558751  1.100566
    three -0.552441  0.493178
    two   -0.550180 -0.158604
foo one    0.268042 -2.460569
    three -0.089265  0.631529
    two    0.791271  0.747671
>>> tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',
... 'foo', 'foo', 'qux', 'qux'],
... ['one', 'two', 'one', 'two',
... 'one', 'two', 'one', 'two']]))
>>> index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])
>>> df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])
>>> df2 = df[:4]
>>> df2
                     A         B
first second
bar   one    -0.987923 -2.525478
      two    -1.145656 -1.005945
baz   one    -0.282987 -1.653624
      two    -1.009240 -0.677991
>>> stacked = df2.stack()
>>> stacked
first  second
bar    one     A   -0.987923
               B   -2.525478
       two     A   -1.145656
               B   -1.005945
baz    one     A   -0.282987
               B   -1.653624
       two     A   -1.009240
               B   -0.677991
dtype: float64
>>> stacked.unstack()
                     A         B
first second
bar   one    -0.987923 -2.525478
      two    -1.145656 -1.005945
baz   one    -0.282987 -1.653624
      two    -1.009240 -0.677991
>>> stacked.unstack(1)
second        one       two
first
bar   A -0.987923 -1.145656
      B -2.525478 -1.005945
baz   A -0.282987 -1.009240
      B -1.653624 -0.677991
>>> stacked.unstack(0)
first          bar       baz
second
one    A -0.987923 -0.282987
       B -2.525478 -1.653624
two    A -1.145656 -1.009240
       B -1.005945 -0.677991
>>> df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three']
...  'B' : ['A', 'B', 'C'] * 4,
  File "<stdin>", line 2
    'B' : ['A', 'B', 'C'] * 4,
      ^
SyntaxError: invalid syntax
>>> 'B' : ['A', 'B', 'C'] * 4,
  File "<stdin>", line 1
    'B' : ['A', 'B', 'C'] * 4,
                             ^
SyntaxError: invalid syntax
>>> df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three']
... 'B' : ['A', 'B', 'C'] * 4,
  File "<stdin>", line 2
    'B' : ['A', 'B', 'C'] * 4,
      ^
SyntaxError: invalid syntax
>>> df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three']
... 'B' : ['A', 'B', 'C'] * 4,
  File "<stdin>", line 2
    'B' : ['A', 'B', 'C'] * 4,
      ^
SyntaxError: invalid syntax
>>> df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,
... 'B' : ['A', 'B', 'C'] * 4,
... 'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,
... 'D' : np.random.randn(12),
... 'E' : np.random.randn(12)})
>>> df
        A  B    C         D         E
0     one  A  foo -0.168260 -1.609663
1     one  B  foo -1.679511  0.772168
2     two  C  foo  0.674914  0.323800
3   three  A  bar  2.199382  0.389289
4     one  B  bar  0.059740 -1.359239
5     one  C  bar -0.055784 -0.743113
6     two  A  foo  0.414491  0.222901
7   three  B  foo  0.899941 -0.119275
8     one  C  foo -2.250242  0.440577
9     one  A  bar -0.222280 -0.804166
10    two  B  bar -0.842671 -0.056825
11  three  C  bar  0.415351 -1.235868
>>> pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])
C             bar       foo
A     B
one   A -0.222280 -0.168260
      B  0.059740 -1.679511
      C -0.055784 -2.250242
three A  2.199382       NaN
      B       NaN  0.899941
      C  0.415351       NaN
two   A       NaN  0.414491
      B -0.842671       NaN
      C       NaN  0.674914
>>> rng = pd.date_range('1/1/2012', periods=100, freq='S')
>>> ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)
>>> ts.resample('5Min').sum()
2012-01-01    24749
Freq: 5T, dtype: int32
>>> rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')
>>> ts = pd.Series(np.random.randn(len(rng)), rng)
>>> ts
2012-03-06   -0.905412
2012-03-07    0.797124
2012-03-08   -0.954302
2012-03-09    2.223183
2012-03-10   -1.760072
Freq: D, dtype: float64
>>> ps = ts.to_period()
>>> ps
2012-03-06   -0.905412
2012-03-07    0.797124
2012-03-08   -0.954302
2012-03-09    2.223183
2012-03-10   -1.760072
Freq: D, dtype: float64
>>> ps.to_timestamp()
2012-03-06   -0.905412
2012-03-07    0.797124
2012-03-08   -0.954302
2012-03-09    2.223183
2012-03-10   -1.760072
Freq: D, dtype: float64
>>> prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')
>>> ts = pd.Series(np.random.randn(len(prng)), prng)
>>> ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9
>>> ts.head()
1990-03-01 09:00    1.268168
1990-06-01 09:00   -0.877427
1990-09-01 09:00    0.989509
1990-12-01 09:00    0.744902
1991-03-01 09:00    1.291609
Freq: H, dtype: float64
>>> df = pd.DataFrame({"id":[1,2,3,4,5,6], "raw_grade":['a', 'b', 'b', 'a', 'a', 'e']})
>>> df["grade"] = df["raw_grade"].astype("category")
>>> df["grade"]
0    a
1    b
2    b
3    a
4    a
5    e
Name: grade, dtype: category
Categories (3, object): [a, b, e]
>>> df["grade"].cat.categories = ["very good", "good", "very bad"]
>>> df["grade"] = df["grade"].cat.set_categories(["very bad", "bad", "medium", "good", "very good"])
>>> df["grade"]
0    very good
1         good
2         good
3    very good
4    very good
5     very bad
Name: grade, dtype: category
Categories (5, object): [very bad, bad, medium, good, very good]
>>> df.sort_values(by="grade")
   id raw_grade      grade
5   6         e   very bad
1   2         b       good
2   3         b       good
0   1         a  very good
3   4         a  very good
4   5         a  very good
>>> df.groupby("grade").size()
grade
very bad     1
bad          0
medium       0
good         2
very good    3
dtype: int64
>>> ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))
>>>
>>> ts = ts.cumsum()
>>> ts.plot()
<matplotlib.axes._subplots.AxesSubplot object at 0x00BB6470>
>>> df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
... columns=['A', 'B', 'C', 'D'])
>>> df = df.cumsum()
>>> plt.figure(); df.plot(); plt.legend(loc='best')
<matplotlib.figure.Figure object at 0x0D3D7BB0>
<matplotlib.axes._subplots.AxesSubplot object at 0x0D3F69D0>
<matplotlib.legend.Legend object at 0x0D3CA5B0>
>>> df.to_csv('foo.csv')
>>> pd.read_csv('foo.csv')
     Unnamed: 0          A          B          C          D
0    2000-01-01   0.754421   0.495517   0.012676   0.487785
1    2000-01-02   1.917138   0.950240   1.414949   0.922241
2    2000-01-03   1.338458   0.885308   2.811178  -0.553444
3    2000-01-04   1.408724   2.878230   1.513690  -0.511483
4    2000-01-05   1.562038   2.723027   2.582556  -0.887940
5    2000-01-06  -0.238319   2.147692   1.327538  -1.178917
6    2000-01-07  -2.363966   2.053209   2.505522  -1.483635
7    2000-01-08  -1.758252   2.272831   0.788497  -3.459058
8    2000-01-09  -3.129167   0.953887   1.090074  -4.693419
9    2000-01-10  -4.759403   2.010590   1.211739  -5.130797
10   2000-01-11  -5.415273   0.750019   2.648568  -6.716707
11   2000-01-12  -6.082911   1.696522   1.039596  -6.598063
12   2000-01-13  -6.449688   2.508475   0.171284  -6.154586
13   2000-01-14  -7.278941   3.660975  -0.164716  -5.595510
14   2000-01-15  -6.645908   4.101093  -1.209930  -6.352106
15   2000-01-16  -5.339805   4.013613  -1.760581  -7.658834
16   2000-01-17  -5.012191   3.511781  -1.105770  -6.885996
17   2000-01-18  -4.075496   2.811426   0.455750  -4.980851
18   2000-01-19  -4.142852   3.160009   0.442840  -4.327055
19   2000-01-20  -3.398870   4.964324   0.067388  -4.902518
20   2000-01-21  -3.353825   4.257659  -0.968780  -4.365830
21   2000-01-22  -4.792243   3.974187  -1.450073  -6.177534
22   2000-01-23  -5.303574   4.974650  -2.186681  -5.993900
23   2000-01-24  -6.180241   6.648771  -3.850334  -5.859848
24   2000-01-25  -4.560136   6.344052  -3.371554  -6.601176
25   2000-01-26  -4.345727   6.684424  -3.648829  -5.849541
26   2000-01-27  -3.586864   6.754149  -5.065734  -4.369677
27   2000-01-28  -0.843394   8.584041  -5.482472  -4.404526
28   2000-01-29  -0.817034   7.690221  -5.490635  -4.648933
29   2000-01-30  -0.373555   6.329342  -6.943258  -4.986983
..          ...        ...        ...        ...        ...
970  2002-08-28 -31.752428 -62.098071 -53.168348  14.327503
971  2002-08-29 -32.602077 -63.246974 -52.729807  13.149934
972  2002-08-30 -32.585296 -62.747299 -50.911408  12.679992
973  2002-08-31 -32.356831 -63.293231 -50.705662  12.466092
974  2002-09-01 -32.963278 -61.758333 -53.212916  13.274724
975  2002-09-02 -32.182180 -61.789231 -52.780192  12.665493
976  2002-09-03 -32.802328 -60.938963 -53.649869  13.912675
977  2002-09-04 -33.509612 -59.886883 -53.676555  14.817236
978  2002-09-05 -32.775069 -59.770226 -53.608311  14.685762
979  2002-09-06 -33.676463 -61.200257 -53.653859  13.887788
980  2002-09-07 -33.818561 -60.906612 -53.437073  14.261336
981  2002-09-08 -33.478138 -59.782554 -54.697276  14.281437
982  2002-09-09 -33.829865 -59.826568 -53.647279  13.728304
983  2002-09-10 -35.687986 -59.029434 -53.332748  15.112463
984  2002-09-11 -37.799659 -59.886565 -53.159778  16.122287
985  2002-09-12 -37.163097 -60.092060 -52.661420  15.514203
986  2002-09-13 -36.723733 -59.622688 -51.264302  15.919993
987  2002-09-14 -35.635009 -58.671100 -48.970513  16.171138
988  2002-09-15 -35.070263 -57.833258 -49.251977  16.311999
989  2002-09-16 -33.078103 -57.682339 -48.443224  16.789344
990  2002-09-17 -33.024510 -55.336056 -49.420712  16.424828
991  2002-09-18 -32.720982 -55.138658 -48.954260  15.486669
992  2002-09-19 -33.381208 -53.916238 -47.633133  15.320761
993  2002-09-20 -33.145756 -55.354515 -46.635320  16.688910
994  2002-09-21 -32.779158 -54.023196 -46.609293  15.891024
995  2002-09-22 -32.536888 -54.231103 -45.799206  15.564054
996  2002-09-23 -32.992923 -54.153286 -45.638897  14.737784
997  2002-09-24 -33.344791 -54.806273 -46.341110  15.720684
998  2002-09-25 -33.451975 -53.322199 -46.184093  17.764822
999  2002-09-26 -34.102546 -51.822572 -46.856995  17.016933

[1000 rows x 5 columns]
